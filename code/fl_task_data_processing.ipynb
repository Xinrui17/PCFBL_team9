{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhe33/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-24cdcfb30e1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpectralClustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import pickle\n",
    "pd.options.mode.chained_assignment = None\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "from collections import OrderedDict\n",
    "from sklearn.cluster import KMeans\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import SpectralClustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f84d1",
   "metadata": {},
   "source": [
    "# 1.Introduction\n",
    "This is an introduction to your report, you should edit this text/mardown section to compose. In this text/markdown, you should introduce:\n",
    "\n",
    "*   Background of the problem\n",
    "  * Type of problem: mortality prediction task\n",
    "  * what is the importance/meaning of solving the problem\n",
    "  * what is the difficulty of the problem\n",
    "  * the state of the art methods and effectiveness.\n",
    "*   Paper explanation\n",
    "  * what did the paper propose\n",
    "  * what is the innovations of the method\n",
    "  * how well the proposed method work (in its own metrics)\n",
    "  * what is the contribution to the reasearch regime (referring the Background above, how important the paper is to the problem).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5823f80",
   "metadata": {},
   "source": [
    "# 2.Scope of Reproducibility:\n",
    "\n",
    "Hypothesis : Performance improvement, PCBFL achieves a statistically significant improvement in\n",
    "predictive performance (e.g., AUC, AUPRC) for mortality prediction tasks over traditional\n",
    "Federated Learning (FL) and Clustered Federated Learning (CFL) without patient clustering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9006d4",
   "metadata": {},
   "source": [
    "##  3.Data\n",
    "Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
    "  * Source of the data: data can be downloaded from the publicly available eICU dataset (https://physionet.org/content/eicu-crd/2.0/)\n",
    "  * Statistics: Data was randomly split into training and testing datasets in a 70:30 ratio. Since only 20% of the labels were positive, we evaluated performance with both AUC and AUPRC scores. We ran the models for 100 times and calculated the mean scores.\n",
    "  * Data process: For the different datasets, we first load the data and show the content of the dataset. Then we extract the corresponding features and filter for data in first 48 hours. We have the different filtering details with different datasets.\n",
    "  * Illustration: we print the fisrt rows of the original datasets and those after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = '/home/xhe33/pcfbl/'\n",
    "PATH_SAVE = '/home/xhe33/pcfbl/'\n",
    "PATH = '/home/xhe33/pcfbl/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xhe33/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "patient = pd.read_csv(f'{PATH_DATA}patient.csv.gz')\n",
    "drugs = pd.read_csv(f'{PATH_DATA}medication.csv.gz')\n",
    "diagnosis = pd.read_csv(f'{PATH_DATA}diagnosis.csv.gz')\n",
    "obs = pd.read_csv(f'{PATH_DATA}physicalExam.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Physiologic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processGCS(df):\n",
    "    pattern = r'GCS/(\\w+)\\sScore/(\\d+)'\n",
    "    gcs_y = []\n",
    "    for entry in df['physicalexampath']:\n",
    "        match = re.search(pattern, entry)\n",
    "        if match:\n",
    "            y_value = match.group(1)\n",
    "            gcs_y.append(f'GCS_{y_value}')\n",
    "        else:\n",
    "            gcs_y.append(f'GCS_total')\n",
    "    df['physicalexamvalue'] = gcs_y\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>physicalexamid</th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>physicalexamoffset</th>\n",
       "      <th>physicalexampath</th>\n",
       "      <th>physicalexamvalue</th>\n",
       "      <th>physicalexamtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5253099</td>\n",
       "      <td>176895</td>\n",
       "      <td>9</td>\n",
       "      <td>notes/Progress Notes/Physical Exam/Physical Ex...</td>\n",
       "      <td>scored</td>\n",
       "      <td>scored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5253100</td>\n",
       "      <td>176895</td>\n",
       "      <td>9</td>\n",
       "      <td>notes/Progress Notes/Physical Exam/Physical Ex...</td>\n",
       "      <td>Performed - Structured</td>\n",
       "      <td>Performed - Structured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5253104</td>\n",
       "      <td>176895</td>\n",
       "      <td>9</td>\n",
       "      <td>notes/Progress Notes/Physical Exam/Physical Ex...</td>\n",
       "      <td>Current</td>\n",
       "      <td>68.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5253105</td>\n",
       "      <td>176895</td>\n",
       "      <td>9</td>\n",
       "      <td>notes/Progress Notes/Physical Exam/Physical Ex...</td>\n",
       "      <td>Intake Total</td>\n",
       "      <td>2725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5253106</td>\n",
       "      <td>176895</td>\n",
       "      <td>9</td>\n",
       "      <td>notes/Progress Notes/Physical Exam/Physical Ex...</td>\n",
       "      <td>Output Total</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   physicalexamid  patientunitstayid  physicalexamoffset  \\\n",
       "0         5253099             176895                   9   \n",
       "1         5253100             176895                   9   \n",
       "2         5253104             176895                   9   \n",
       "3         5253105             176895                   9   \n",
       "4         5253106             176895                   9   \n",
       "\n",
       "                                    physicalexampath       physicalexamvalue  \\\n",
       "0  notes/Progress Notes/Physical Exam/Physical Ex...                  scored   \n",
       "1  notes/Progress Notes/Physical Exam/Physical Ex...  Performed - Structured   \n",
       "2  notes/Progress Notes/Physical Exam/Physical Ex...                 Current   \n",
       "3  notes/Progress Notes/Physical Exam/Physical Ex...            Intake Total   \n",
       "4  notes/Progress Notes/Physical Exam/Physical Ex...            Output Total   \n",
       "\n",
       "         physicalexamtext  \n",
       "0                  scored  \n",
       "1  Performed - Structured  \n",
       "2                    68.3  \n",
       "3                    2725  \n",
       "4                    1360  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Observations\n",
    "obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Extract the physiologic data\n",
    "pattern = r'^-?\\d+$'\n",
    "#Get GCS\n",
    "gcs = obs[obs['physicalexampath'].str.contains('GCS')]\n",
    "gcs_ = gcs[gcs['physicalexamtext'].apply(lambda x: bool(re.match(pattern, str(x))))]\n",
    "gcs_ = processGCS(gcs_)\n",
    "gcs_ = gcs_[gcs_['physicalexamvalue'] != 'GCS_total']\n",
    "\n",
    "#Get Vitals\n",
    "vs = obs[obs['physicalexampath'].str.contains('Vital Sign')]\n",
    "vitals = ['HR Current', 'BP (systolic) Current', 'Resp Current', 'O2 Sat% Current']\n",
    "vs_ = vs[vs['physicalexamvalue'].isin(vitals)]\n",
    "vs_ = vs_[vs_['physicalexamtext'].apply(lambda x: bool(re.match(pattern, str(x))))]\n",
    "\n",
    "#Merge\n",
    "physio = pd.concat([gcs_, vs_])\n",
    "physio['physicalexamtext'] = physio['physicalexamtext'].astype(int)\n",
    "physio_ = physio[['patientunitstayid','physicalexamoffset', 'physicalexamvalue', 'physicalexamtext']]\n",
    "physio_.rename(columns = {'physicalexamvalue':'exam', 'physicalexamtext': 'value'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for data in first 48 hours\n",
    "MINUTES  = 48*60\n",
    "physio_ = physio_[physio_['physicalexamoffset'] <= MINUTES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Get patients with full coverage\n",
    "coverage = pd.DataFrame(physio_.groupby('patientunitstayid')['exam'].unique())\n",
    "coverage['count'] = coverage['exam'].apply(lambda x: len(x))\n",
    "full_covered = coverage[coverage['count'] == 7]\n",
    "PIDS_PHYS = list(full_covered.index)\n",
    "\n",
    "#Filter data for these patients\n",
    "physio_pts = physio_[physio_['patientunitstayid'].isin(PIDS_PHYS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medicationid</th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>drugorderoffset</th>\n",
       "      <th>drugstartoffset</th>\n",
       "      <th>drugivadmixture</th>\n",
       "      <th>drugordercancelled</th>\n",
       "      <th>drugname</th>\n",
       "      <th>drughiclseqno</th>\n",
       "      <th>dosage</th>\n",
       "      <th>routeadmin</th>\n",
       "      <th>frequency</th>\n",
       "      <th>loadingdose</th>\n",
       "      <th>prn</th>\n",
       "      <th>drugstopoffset</th>\n",
       "      <th>gtc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7426715</td>\n",
       "      <td>141168</td>\n",
       "      <td>309</td>\n",
       "      <td>666</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>METOPROLOL TARTRATE 25 MG PO TABS</td>\n",
       "      <td>2102.0</td>\n",
       "      <td>25 3</td>\n",
       "      <td>PO</td>\n",
       "      <td>Q12H SCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>1826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9643232</td>\n",
       "      <td>141168</td>\n",
       "      <td>1847</td>\n",
       "      <td>1832</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3 ML  -  IPRATROPIUM-ALBUTEROL 0.5-2.5 (3) MG/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 1</td>\n",
       "      <td>NEBULIZATION</td>\n",
       "      <td>Q4H Resp PRN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10270090</td>\n",
       "      <td>141168</td>\n",
       "      <td>296</td>\n",
       "      <td>1386</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>ASPIRIN EC 81 MG PO TBEC</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>81 3</td>\n",
       "      <td>PO</td>\n",
       "      <td>Daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>2390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9496768</td>\n",
       "      <td>141168</td>\n",
       "      <td>2048</td>\n",
       "      <td>2029</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3 ML  -  IPRATROPIUM-ALBUTEROL 0.5-2.5 (3) MG/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 1</td>\n",
       "      <td>NEBULIZATION</td>\n",
       "      <td>Q4H Resp PRN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11259680</td>\n",
       "      <td>141168</td>\n",
       "      <td>117</td>\n",
       "      <td>246</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>ENOXAPARIN SODIUM 40 MG/0.4ML SC SOLN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40 3</td>\n",
       "      <td>SC</td>\n",
       "      <td>Daily</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>1721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   medicationid  patientunitstayid  drugorderoffset  drugstartoffset  \\\n",
       "0       7426715             141168              309              666   \n",
       "1       9643232             141168             1847             1832   \n",
       "2      10270090             141168              296             1386   \n",
       "3       9496768             141168             2048             2029   \n",
       "4      11259680             141168              117              246   \n",
       "\n",
       "  drugivadmixture drugordercancelled  \\\n",
       "0              No                 No   \n",
       "1              No                 No   \n",
       "2              No                 No   \n",
       "3              No                 No   \n",
       "4              No                 No   \n",
       "\n",
       "                                            drugname  drughiclseqno dosage  \\\n",
       "0                  METOPROLOL TARTRATE 25 MG PO TABS         2102.0   25 3   \n",
       "1  3 ML  -  IPRATROPIUM-ALBUTEROL 0.5-2.5 (3) MG/...            NaN    3 1   \n",
       "2                           ASPIRIN EC 81 MG PO TBEC         1820.0   81 3   \n",
       "3  3 ML  -  IPRATROPIUM-ALBUTEROL 0.5-2.5 (3) MG/...            NaN    3 1   \n",
       "4              ENOXAPARIN SODIUM 40 MG/0.4ML SC SOLN            NaN   40 3   \n",
       "\n",
       "     routeadmin     frequency loadingdose  prn  drugstopoffset  gtc  \n",
       "0            PO      Q12H SCH         NaN   No            1826    0  \n",
       "1  NEBULIZATION  Q4H Resp PRN         NaN  Yes            2047    0  \n",
       "2            PO         Daily         NaN   No            2390    0  \n",
       "3  NEBULIZATION  Q4H Resp PRN         NaN  Yes            2390    0  \n",
       "4            SC         Daily         NaN   No            1721    0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for drugs administered in the first 48 hours of admit\n",
    "MINUTES  = 48*60\n",
    "drugs = drugs[(drugs['drugordercancelled'] == 'No') & (drugs['drugstartoffset'] <= MINUTES)]\n",
    "drugs_ = drugs[['patientunitstayid' ,'drugname']]\n",
    "drugs_.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map names to integers\n",
    "names = list(drugs_['drugname'].unique())\n",
    "values = [i for i in range(1, len(names)+1)]\n",
    "mapping = dict(zip(names, values))\n",
    "mapping_back = dict(zip(values, names))\n",
    "drugs_['drugid'] = drugs_['drugname'].map(mapping)\n",
    "drugs_ = drugs_[['patientunitstayid', 'drugid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract those with at least 4 medications\n",
    "PIDS_MED = drugs_.groupby('patientunitstayid').count().loc[lambda x: x['drugid'] >= 4].index.tolist()\n",
    "drugs_pts = drugs_[drugs_['patientunitstayid'].isin(PIDS_MED)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_4digit_icd9(dxStr):\n",
    "\tif dxStr.startswith('E') != True:\n",
    "\t\tif len(dxStr) > 5: return dxStr[:5]\n",
    "\t\telse: return dxStr\n",
    "\telse:\n",
    "\t\tif len(dxStr) > 6: return dxStr[:6]\n",
    "\t\telse: return dxStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosisid</th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>activeupondischarge</th>\n",
       "      <th>diagnosisoffset</th>\n",
       "      <th>diagnosisstring</th>\n",
       "      <th>icd9code</th>\n",
       "      <th>diagnosispriority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4222318</td>\n",
       "      <td>141168</td>\n",
       "      <td>False</td>\n",
       "      <td>72</td>\n",
       "      <td>cardiovascular|chest pain / ASHD|coronary arte...</td>\n",
       "      <td>414.00, I25.10</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3370568</td>\n",
       "      <td>141168</td>\n",
       "      <td>True</td>\n",
       "      <td>118</td>\n",
       "      <td>cardiovascular|ventricular disorders|cardiomyo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4160941</td>\n",
       "      <td>141168</td>\n",
       "      <td>False</td>\n",
       "      <td>72</td>\n",
       "      <td>pulmonary|disorders of the airways|COPD</td>\n",
       "      <td>491.20, J44.9</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4103261</td>\n",
       "      <td>141168</td>\n",
       "      <td>True</td>\n",
       "      <td>118</td>\n",
       "      <td>pulmonary|disorders of the airways|COPD</td>\n",
       "      <td>491.20, J44.9</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3545241</td>\n",
       "      <td>141168</td>\n",
       "      <td>True</td>\n",
       "      <td>118</td>\n",
       "      <td>cardiovascular|ventricular disorders|congestiv...</td>\n",
       "      <td>428.0, I50.9</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosisid  patientunitstayid  activeupondischarge  diagnosisoffset  \\\n",
       "0      4222318             141168                False               72   \n",
       "1      3370568             141168                 True              118   \n",
       "2      4160941             141168                False               72   \n",
       "3      4103261             141168                 True              118   \n",
       "4      3545241             141168                 True              118   \n",
       "\n",
       "                                     diagnosisstring        icd9code  \\\n",
       "0  cardiovascular|chest pain / ASHD|coronary arte...  414.00, I25.10   \n",
       "1  cardiovascular|ventricular disorders|cardiomyo...             NaN   \n",
       "2            pulmonary|disorders of the airways|COPD   491.20, J44.9   \n",
       "3            pulmonary|disorders of the airways|COPD   491.20, J44.9   \n",
       "4  cardiovascular|ventricular disorders|congestiv...    428.0, I50.9   \n",
       "\n",
       "  diagnosispriority  \n",
       "0             Other  \n",
       "1             Other  \n",
       "2             Other  \n",
       "3             Other  \n",
       "4             Other  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process codes\n",
    "dx_codes = diagnosis[['patientunitstayid']]\n",
    "dx_codes['icd9code'] = diagnosis['icd9code'].str.split(',').str.get(0)\n",
    "dx_codes.dropna(inplace = True)\n",
    "dx_codes['icd9code'] = dx_codes['icd9code'].apply(convert_to_4digit_icd9)\n",
    "#Filter icd9code\n",
    "pattern = re.compile(r'^\\D+')\n",
    "dx_codes = dx_codes[dx_codes['icd9code'].str.contains(pattern) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract those with at last 4 dx\n",
    "PIDS_DX = dx_codes.groupby('patientunitstayid').count().loc[lambda x: x['icd9code'] >= 3].index.tolist()\n",
    "dx_pts = dx_codes[dx_codes['patientunitstayid'].isin(PIDS_DX)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>patienthealthsystemstayid</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>hospitalid</th>\n",
       "      <th>wardid</th>\n",
       "      <th>apacheadmissiondx</th>\n",
       "      <th>admissionheight</th>\n",
       "      <th>hospitaladmittime24</th>\n",
       "      <th>...</th>\n",
       "      <th>unitadmitsource</th>\n",
       "      <th>unitvisitnumber</th>\n",
       "      <th>unitstaytype</th>\n",
       "      <th>admissionweight</th>\n",
       "      <th>dischargeweight</th>\n",
       "      <th>unitdischargetime24</th>\n",
       "      <th>unitdischargeoffset</th>\n",
       "      <th>unitdischargelocation</th>\n",
       "      <th>unitdischargestatus</th>\n",
       "      <th>uniquepid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141168</td>\n",
       "      <td>128919</td>\n",
       "      <td>Female</td>\n",
       "      <td>70</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>59</td>\n",
       "      <td>91</td>\n",
       "      <td>Rhythm disturbance (atrial, supraventricular)</td>\n",
       "      <td>152.4</td>\n",
       "      <td>15:54:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Direct Admit</td>\n",
       "      <td>1</td>\n",
       "      <td>admit</td>\n",
       "      <td>84.3</td>\n",
       "      <td>85.8</td>\n",
       "      <td>03:50:00</td>\n",
       "      <td>3596</td>\n",
       "      <td>Death</td>\n",
       "      <td>Expired</td>\n",
       "      <td>002-34851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141178</td>\n",
       "      <td>128927</td>\n",
       "      <td>Female</td>\n",
       "      <td>52</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>60</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.6</td>\n",
       "      <td>08:56:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>1</td>\n",
       "      <td>admit</td>\n",
       "      <td>54.4</td>\n",
       "      <td>54.4</td>\n",
       "      <td>09:18:00</td>\n",
       "      <td>8</td>\n",
       "      <td>Step-Down Unit (SDU)</td>\n",
       "      <td>Alive</td>\n",
       "      <td>002-33870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141179</td>\n",
       "      <td>128927</td>\n",
       "      <td>Female</td>\n",
       "      <td>52</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>60</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.6</td>\n",
       "      <td>08:56:00</td>\n",
       "      <td>...</td>\n",
       "      <td>ICU to SDU</td>\n",
       "      <td>2</td>\n",
       "      <td>stepdown/other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.4</td>\n",
       "      <td>19:20:00</td>\n",
       "      <td>2042</td>\n",
       "      <td>Home</td>\n",
       "      <td>Alive</td>\n",
       "      <td>002-33870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141194</td>\n",
       "      <td>128941</td>\n",
       "      <td>Male</td>\n",
       "      <td>68</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>73</td>\n",
       "      <td>92</td>\n",
       "      <td>Sepsis, renal/UTI (including bladder)</td>\n",
       "      <td>180.3</td>\n",
       "      <td>18:18:40</td>\n",
       "      <td>...</td>\n",
       "      <td>Floor</td>\n",
       "      <td>1</td>\n",
       "      <td>admit</td>\n",
       "      <td>73.9</td>\n",
       "      <td>76.7</td>\n",
       "      <td>15:31:00</td>\n",
       "      <td>4813</td>\n",
       "      <td>Floor</td>\n",
       "      <td>Alive</td>\n",
       "      <td>002-5276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141196</td>\n",
       "      <td>128943</td>\n",
       "      <td>Male</td>\n",
       "      <td>71</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>67</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.6</td>\n",
       "      <td>20:21:00</td>\n",
       "      <td>...</td>\n",
       "      <td>ICU to SDU</td>\n",
       "      <td>2</td>\n",
       "      <td>stepdown/other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.2</td>\n",
       "      <td>22:23:00</td>\n",
       "      <td>1463</td>\n",
       "      <td>Floor</td>\n",
       "      <td>Alive</td>\n",
       "      <td>002-37665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientunitstayid  patienthealthsystemstayid  gender age  ethnicity  \\\n",
       "0             141168                     128919  Female  70  Caucasian   \n",
       "1             141178                     128927  Female  52  Caucasian   \n",
       "2             141179                     128927  Female  52  Caucasian   \n",
       "3             141194                     128941    Male  68  Caucasian   \n",
       "4             141196                     128943    Male  71  Caucasian   \n",
       "\n",
       "   hospitalid  wardid                              apacheadmissiondx  \\\n",
       "0          59      91  Rhythm disturbance (atrial, supraventricular)   \n",
       "1          60      83                                            NaN   \n",
       "2          60      83                                            NaN   \n",
       "3          73      92          Sepsis, renal/UTI (including bladder)   \n",
       "4          67     109                                            NaN   \n",
       "\n",
       "   admissionheight hospitaladmittime24  ...       unitadmitsource  \\\n",
       "0            152.4            15:54:00  ...          Direct Admit   \n",
       "1            162.6            08:56:00  ...  Emergency Department   \n",
       "2            162.6            08:56:00  ...            ICU to SDU   \n",
       "3            180.3            18:18:40  ...                 Floor   \n",
       "4            162.6            20:21:00  ...            ICU to SDU   \n",
       "\n",
       "  unitvisitnumber    unitstaytype admissionweight  dischargeweight  \\\n",
       "0               1           admit            84.3             85.8   \n",
       "1               1           admit            54.4             54.4   \n",
       "2               2  stepdown/other             NaN             60.4   \n",
       "3               1           admit            73.9             76.7   \n",
       "4               2  stepdown/other             NaN             63.2   \n",
       "\n",
       "  unitdischargetime24 unitdischargeoffset unitdischargelocation  \\\n",
       "0            03:50:00                3596                 Death   \n",
       "1            09:18:00                   8  Step-Down Unit (SDU)   \n",
       "2            19:20:00                2042                  Home   \n",
       "3            15:31:00                4813                 Floor   \n",
       "4            22:23:00                1463                 Floor   \n",
       "\n",
       "  unitdischargestatus  uniquepid  \n",
       "0             Expired  002-34851  \n",
       "1               Alive  002-33870  \n",
       "2               Alive  002-33870  \n",
       "3               Alive   002-5276  \n",
       "4               Alive  002-37665  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = patient[['patientunitstayid', 'age', 'admissionheight', 'admissionweight']]\n",
    "demo.dropna(inplace = True)\n",
    "PIDS_DEMO = demo['patientunitstayid'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patient intersection of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients with all features: 44842\n"
     ]
    }
   ],
   "source": [
    "PIDS = list(set(PIDS_PHYS).intersection(PIDS_MED).intersection(PIDS_DX).intersection(PIDS_DEMO))\n",
    "print(f\"number of patients with all features: {len(PIDS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientunitstayid</th>\n",
       "      <th>patienthealthsystemstayid</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>hospitalid</th>\n",
       "      <th>wardid</th>\n",
       "      <th>apacheadmissiondx</th>\n",
       "      <th>admissionheight</th>\n",
       "      <th>hospitaladmittime24</th>\n",
       "      <th>...</th>\n",
       "      <th>unitadmitsource</th>\n",
       "      <th>unitvisitnumber</th>\n",
       "      <th>unitstaytype</th>\n",
       "      <th>admissionweight</th>\n",
       "      <th>dischargeweight</th>\n",
       "      <th>unitdischargetime24</th>\n",
       "      <th>unitdischargeoffset</th>\n",
       "      <th>unitdischargelocation</th>\n",
       "      <th>unitdischargestatus</th>\n",
       "      <th>uniquepid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141168</td>\n",
       "      <td>128919</td>\n",
       "      <td>Female</td>\n",
       "      <td>70</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>59</td>\n",
       "      <td>91</td>\n",
       "      <td>Rhythm disturbance (atrial, supraventricular)</td>\n",
       "      <td>152.4</td>\n",
       "      <td>15:54:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Direct Admit</td>\n",
       "      <td>1</td>\n",
       "      <td>admit</td>\n",
       "      <td>84.3</td>\n",
       "      <td>85.8</td>\n",
       "      <td>03:50:00</td>\n",
       "      <td>3596</td>\n",
       "      <td>Death</td>\n",
       "      <td>Expired</td>\n",
       "      <td>002-34851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141178</td>\n",
       "      <td>128927</td>\n",
       "      <td>Female</td>\n",
       "      <td>52</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>60</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.6</td>\n",
       "      <td>08:56:00</td>\n",
       "      <td>...</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>1</td>\n",
       "      <td>admit</td>\n",
       "      <td>54.4</td>\n",
       "      <td>54.4</td>\n",
       "      <td>09:18:00</td>\n",
       "      <td>8</td>\n",
       "      <td>Step-Down Unit (SDU)</td>\n",
       "      <td>Alive</td>\n",
       "      <td>002-33870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141179</td>\n",
       "      <td>128927</td>\n",
       "      <td>Female</td>\n",
       "      <td>52</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>60</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.6</td>\n",
       "      <td>08:56:00</td>\n",
       "      <td>...</td>\n",
       "      <td>ICU to SDU</td>\n",
       "      <td>2</td>\n",
       "      <td>stepdown/other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.4</td>\n",
       "      <td>19:20:00</td>\n",
       "      <td>2042</td>\n",
       "      <td>Home</td>\n",
       "      <td>Alive</td>\n",
       "      <td>002-33870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141194</td>\n",
       "      <td>128941</td>\n",
       "      <td>Male</td>\n",
       "      <td>68</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>73</td>\n",
       "      <td>92</td>\n",
       "      <td>Sepsis, renal/UTI (including bladder)</td>\n",
       "      <td>180.3</td>\n",
       "      <td>18:18:40</td>\n",
       "      <td>...</td>\n",
       "      <td>Floor</td>\n",
       "      <td>1</td>\n",
       "      <td>admit</td>\n",
       "      <td>73.9</td>\n",
       "      <td>76.7</td>\n",
       "      <td>15:31:00</td>\n",
       "      <td>4813</td>\n",
       "      <td>Floor</td>\n",
       "      <td>Alive</td>\n",
       "      <td>002-5276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141196</td>\n",
       "      <td>128943</td>\n",
       "      <td>Male</td>\n",
       "      <td>71</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>67</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.6</td>\n",
       "      <td>20:21:00</td>\n",
       "      <td>...</td>\n",
       "      <td>ICU to SDU</td>\n",
       "      <td>2</td>\n",
       "      <td>stepdown/other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.2</td>\n",
       "      <td>22:23:00</td>\n",
       "      <td>1463</td>\n",
       "      <td>Floor</td>\n",
       "      <td>Alive</td>\n",
       "      <td>002-37665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patientunitstayid  patienthealthsystemstayid  gender age  ethnicity  \\\n",
       "0             141168                     128919  Female  70  Caucasian   \n",
       "1             141178                     128927  Female  52  Caucasian   \n",
       "2             141179                     128927  Female  52  Caucasian   \n",
       "3             141194                     128941    Male  68  Caucasian   \n",
       "4             141196                     128943    Male  71  Caucasian   \n",
       "\n",
       "   hospitalid  wardid                              apacheadmissiondx  \\\n",
       "0          59      91  Rhythm disturbance (atrial, supraventricular)   \n",
       "1          60      83                                            NaN   \n",
       "2          60      83                                            NaN   \n",
       "3          73      92          Sepsis, renal/UTI (including bladder)   \n",
       "4          67     109                                            NaN   \n",
       "\n",
       "   admissionheight hospitaladmittime24  ...       unitadmitsource  \\\n",
       "0            152.4            15:54:00  ...          Direct Admit   \n",
       "1            162.6            08:56:00  ...  Emergency Department   \n",
       "2            162.6            08:56:00  ...            ICU to SDU   \n",
       "3            180.3            18:18:40  ...                 Floor   \n",
       "4            162.6            20:21:00  ...            ICU to SDU   \n",
       "\n",
       "  unitvisitnumber    unitstaytype admissionweight  dischargeweight  \\\n",
       "0               1           admit            84.3             85.8   \n",
       "1               1           admit            54.4             54.4   \n",
       "2               2  stepdown/other             NaN             60.4   \n",
       "3               1           admit            73.9             76.7   \n",
       "4               2  stepdown/other             NaN             63.2   \n",
       "\n",
       "  unitdischargetime24 unitdischargeoffset unitdischargelocation  \\\n",
       "0            03:50:00                3596                 Death   \n",
       "1            09:18:00                   8  Step-Down Unit (SDU)   \n",
       "2            19:20:00                2042                  Home   \n",
       "3            15:31:00                4813                 Floor   \n",
       "4            22:23:00                1463                 Floor   \n",
       "\n",
       "  unitdischargestatus  uniquepid  \n",
       "0             Expired  002-34851  \n",
       "1               Alive  002-33870  \n",
       "2               Alive  002-33870  \n",
       "3               Alive   002-5276  \n",
       "4               Alive  002-37665  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ = patient[patient['patientunitstayid'].isin(PIDS)]\n",
    "mortality = patient_[['patientunitstayid','patienthealthsystemstayid','hospitalid', 'unitdischargestatus']]\n",
    "expired = pd.get_dummies(mortality[['unitdischargestatus']])['unitdischargestatus_Expired']\n",
    "mortality['expired'] = expired\n",
    "mortality = mortality[['patientunitstayid', 'patienthealthsystemstayid', 'hospitalid', 'expired']]\n",
    "los = patient_[['patientunitstayid', 'patienthealthsystemstayid', 'hospitalid', 'unitdischargeoffset']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Patient sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##select hospitals with positive cases (otherwise model fails)\n",
    "def get_hospitals(unique_pt, TOTAL = 250, POS = 50):\n",
    "    grouped_pt = unique_pt.groupby(['hospitalid', 'expired']).agg({'patienthealthsystemstayid': 'count'})\n",
    "    pos_h = grouped_pt.loc[grouped_pt.index.get_level_values('expired') == 1][\n",
    "        grouped_pt.loc[grouped_pt.index.get_level_values('expired') == 1, 'patienthealthsystemstayid'] >= POS\n",
    "        ].index.get_level_values('hospitalid')\n",
    "    neg_h =   grouped_pt.loc[grouped_pt.index.get_level_values('expired') == 0][\n",
    "        grouped_pt.loc[grouped_pt.index.get_level_values('expired') == 0, 'patienthealthsystemstayid'] >= TOTAL - POS\n",
    "        ].index.get_level_values('hospitalid')\n",
    "\n",
    "    hospitals = list(set(neg_h).intersection(set(pos_h)))\n",
    "    return hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_group(group, TOTAL = 250, POS = 50):\n",
    "    expired_1 = group[group['expired'] == 1]\n",
    "    expired_0 = group[group['expired'] == 0]\n",
    "    n_expired_1 = POS\n",
    "    n_expired_0 = TOTAL-POS\n",
    "    sample_expired_1 = expired_1.sample(n=n_expired_1, random_state=1)\n",
    "    sample_expired_0 = expired_0.sample(n=n_expired_0, random_state=1)\n",
    "    samples = pd.concat([sample_expired_1, sample_expired_0])\n",
    "    return samples.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first stay for a patient\n",
    "outcome = mortality.merge(los[['patientunitstayid', 'unitdischargeoffset']], on = 'patientunitstayid')\n",
    "outcome = outcome.groupby('patienthealthsystemstayid').min('unitdischargeoffset').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of hospitals: 20, number of patients: 20221\n"
     ]
    }
   ],
   "source": [
    "# Filter hosptials 100 positive patients and 300 overall\n",
    "unique_pt = outcome[['hospitalid','patienthealthsystemstayid', 'patientunitstayid', 'expired']]\n",
    "hosp_counts = unique_pt.groupby('hospitalid').count()[['patienthealthsystemstayid']]\n",
    "hospitals = get_hospitals(unique_pt)\n",
    "hosp_pts = unique_pt[unique_pt['hospitalid'].isin(hospitals)]\n",
    "print(f\"number of hospitals: {hosp_pts['hospitalid'].nunique()}, number of patients: {hosp_pts['patientunitstayid'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each hospital randomly sample 300 patients\n",
    "selected_patients = hosp_pts.groupby('hospitalid').apply(sample_group)\n",
    "selected_patients.reset_index(level=0, drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Filter datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter patients in datasets\n",
    "##mortality\n",
    "mortality_final = mortality[mortality['patientunitstayid'].isin(selected_patients['patientunitstayid'])]\n",
    "##los\n",
    "los_final = los[los['patientunitstayid'].isin(selected_patients['patientunitstayid'])]\n",
    "##features\n",
    "demo_final = demo[demo['patientunitstayid'].isin(selected_patients['patientunitstayid'])]\n",
    "dx_final = dx_pts[dx_pts['patientunitstayid'].isin(selected_patients['patientunitstayid'])]\n",
    "drugs_final = drugs_pts[drugs_pts['patientunitstayid'].isin(selected_patients['patientunitstayid'])]\n",
    "physio_final = physio_pts[physio_pts['patientunitstayid'].isin(selected_patients['patientunitstayid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check PIDS are equal\n",
    "patients_included = []\n",
    "for df in [demo_final, dx_final, drugs_final, physio_final, mortality_final, los_final]:\n",
    "    patients_included.append(df['patientunitstayid'].nunique())\n",
    "len(set(patients_included)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample sizes\n",
    "sample_size = selected_patients.groupby('hospitalid')[['patientunitstayid']].count()\n",
    "sample_size.columns = ['count']\n",
    "sample_size.to_csv(f'{PATH_SAVE}hospitals.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Prcoess datasets for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hospid(df, hosp):\n",
    "    return df.merge(hosp[['patientunitstayid', 'hospitalid']], on = 'patientunitstayid')\n",
    "\n",
    "demo_final = add_hospid(demo_final, mortality)\n",
    "dx_final = add_hospid(dx_final, mortality)\n",
    "drugs_final = add_hospid(drugs_final, mortality)\n",
    "physio_final = add_hospid(physio_final, mortality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map features to integers for model\n",
    "def map_codes_integers(df, column):\n",
    "    names = list(df[column].unique())\n",
    "    values = [i for i in range(1, len(names)+1)]\n",
    "    mapping = dict(zip(names, values))\n",
    "    column_new = f'{column}id'\n",
    "    df[column_new] = df[column].map(mapping)\n",
    "    return mapping, df.drop(columns = column)\n",
    "\n",
    "dx_mapping, dx_final_ = map_codes_integers(dx_final, 'icd9code')\n",
    "physio_mapping, physio_final_ = map_codes_integers(physio_final, 'exam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pivot tables\n",
    "drugs_p = drugs_final[['patientunitstayid', 'drugid']].pivot_table(index='patientunitstayid', columns='drugid', aggfunc=lambda x: x['drugid'].count(), fill_value=0)\n",
    "dx_p = dx_final[['patientunitstayid', 'icd9codeid']].pivot_table(index='patientunitstayid', columns='icd9codeid', aggfunc=lambda x: x['icd9codeid'].count(), fill_value=0)\n",
    "physio_p = physio_final[['patientunitstayid', 'examid', 'value']].pivot_table(index='patientunitstayid', columns='examid', values='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [(mortality_final, 'mortality', False), \n",
    "              (los_final, 'los', False), \n",
    "              (dx_p, 'diagnosis', True), \n",
    "              (drugs_p, 'medications', True), \n",
    "              (physio_p, 'physio', True), \n",
    "              (demo_final, 'demographics', False),\n",
    "              (dx_final, 'diagnosis_raw', False), \n",
    "              (drugs_final, 'medications_raw', False), \n",
    "              (physio_final, 'physio_raw', False)]\n",
    "#All\n",
    "for df, filename, index in dataframes:\n",
    "    df.to_csv(f'{PATH_SAVE}{filename}.csv', index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataframes = [(mortality_final, 'mortality', False), \n",
    "              (los_final, 'los', False), \n",
    "              (dx_p, 'diagnosis', True), \n",
    "              (drugs_p, 'medications', True), \n",
    "              (physio_p, 'physio', True), \n",
    "              (demo_final, 'demographics', False)]\n",
    "#Hospital\n",
    "for hosp in hospitals:\n",
    "    for df, filename, index in dataframes:\n",
    "        if filename in ['diagnosis', 'medications', 'physio']:\n",
    "            df_ = df.merge(mortality_final[['patientunitstayid', 'hospitalid']], left_index = True, right_on = 'patientunitstayid')\n",
    "            df_ = df_[df_['hospitalid'] == hosp]\n",
    "            df_hosp = df_.drop('hospitalid', axis = 1).set_index('patientunitstayid')\n",
    "        else:\n",
    "            df_hosp = df[df['hospitalid'] == hosp]\n",
    "        path_to_save = f'{PATH_SAVE}{hosp}/{filename}.csv'\n",
    "        directory = os.path.dirname(path_to_save)\n",
    "        if not os.path.exists(directory):  \n",
    "            os.makedirs(directory)  \n",
    "        df_hosp.to_csv(path_to_save, index=index)\n",
    "#         df_hosp.to_csv(path_to_save, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PATH_SAVE}drug_map.pickle', 'wb') as file:\n",
    "    pickle.dump(mapping, file)\n",
    "\n",
    "with open(f'{PATH_SAVE}code_icd_map.pickle', 'wb') as file:\n",
    "    pickle.dump(dx_mapping, file)\n",
    "\n",
    "with open(f'{PATH_SAVE}physio_map.pickle', 'wb') as file:\n",
    "    pickle.dump(physio_mapping, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1651f5a1",
   "metadata": {},
   "source": [
    "##   Model\n",
    "The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
    "  * Model architecture: layer number/size/type, activation function, etc\n",
    "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
    "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
    "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
    "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "648147e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_DATA = '/home/xhe33/pcfbl/'\n",
    "PATH_FL_SCRIPT = '/home/xhe33/pcfbl/code/'\n",
    "FT_TYPES = ['meds', 'dx', 'physio']\n",
    "DIMS = {'meds':1056, 'dx':483, 'physio': 7}\n",
    "HOSPITALS=[264,142,148,281,154,283,157,420,165,167,176,449,79,199,458,338,227,248,122,252]\n",
    "N_CLUSTERS = 3\n",
    "MODELTYPE = \"avg\"\n",
    "#MODELS\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim_drugs, input_dim_dx, input_dim_physio):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim_drugs = input_dim_drugs\n",
    "        self.input_dim_dx = input_dim_dx\n",
    "        self.input_dim_physio = input_dim_physio\n",
    "\n",
    "        \n",
    "        self.FF_meds = nn.Sequential(\n",
    "                        nn.Linear(self.input_dim_drugs, 100),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(100, 50),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(50, 10),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(10, 5)\n",
    "                        )\n",
    "        \n",
    "        self.FF_dx = nn.Sequential(\n",
    "                        nn.Linear(self.input_dim_dx, 100),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(100, 50),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(50, 10),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(10, 5)\n",
    "                        )\n",
    "        \n",
    "        self.FF_physio = nn.Sequential(\n",
    "                        nn.Linear(self.input_dim_physio, 40),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(40, 20),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(20, 10),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(10, 5)\n",
    "                        )\n",
    "        \n",
    "        self.FF_multihead = nn.Sequential(\n",
    "                        nn.Linear(15, 15),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(15, 10),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(10, 5),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(5, 1),\n",
    "                        nn.Sigmoid()\n",
    "                        )\n",
    "\n",
    "    def forward(self, x_drugs, x_dx, x_physio):\n",
    "        meds = self.FF_meds(x_drugs)\n",
    "        dx =  self.FF_dx(x_dx)\n",
    "        physio = self.FF_physio(x_physio)\n",
    "        ##concatentate\n",
    "        x_concat = torch.cat((meds, dx, physio), dim = 1)\n",
    "        #run through final head\n",
    "        scores = self.FF_multihead(x_concat)\n",
    "        return scores\n",
    "\n",
    "#FEDAVG\n",
    "def FedAvg(hospitals, global_model, model):\n",
    "    # Load the state dicts for each hospital model and set them to eval mode\n",
    "    hospital_params_list = []\n",
    "    hosps_included = []\n",
    "    try: \n",
    "        for i, hosp in enumerate(hospitals.index):\n",
    "            hospital_params = torch.load(f'{PATH}{hosp}/{model}.pt')\n",
    "            hospital_params_list.append(hospital_params)\n",
    "            hosps_included.append(hosp)\n",
    "    except:\n",
    "        # if site doesnt have cluster\n",
    "        pass\n",
    "    \n",
    "    # Set the weights for each hospital\n",
    "    weights = hospitals.loc[hosps_included]['weight'].values\n",
    "    \n",
    "    # Compute the weighted average of the model parameters\n",
    "    global_params = OrderedDict()\n",
    "    for key in hospital_params_list[0]:\n",
    "        global_params[key] = torch.zeros(hospital_params_list[0][key].shape)\n",
    "    \n",
    "    for i, hospital_params in enumerate(hospital_params_list):\n",
    "        for key in hospital_params:\n",
    "            global_params[key] += hospital_params[key] * weights[i]\n",
    "    \n",
    "    # Set the global model parameters to the averaged parameters\n",
    "    global_model.load_state_dict(global_params)\n",
    "    return global_model\n",
    "\n",
    "def runFedAvg(hospitals, model, mode):\n",
    "    # run for each cluster\n",
    "    if mode == 'all':\n",
    "        dim0, dim1, dim2 = list(DIMS.values())\n",
    "        global_model = FeedForward(dim0, dim1, dim2)\n",
    "        model = f'prediction'\n",
    "        global_model = FedAvg(hospitals, global_model, model)\n",
    "        return global_model\n",
    "    \n",
    "    elif mode == 'cluster':\n",
    "        global_models = {}\n",
    "        for i in range(N_CLUSTERS):\n",
    "            dim0, dim1, dim2 = list(DIMS.values())\n",
    "            global_model = FeedForward(dim0, dim1, dim2)\n",
    "            model = f'prediction_cluster_{i}'\n",
    "            hospitals_cluster = calc_weights(PATH, hospitals, i)\n",
    "            global_model = FedAvg(hospitals_cluster, global_model, model)\n",
    "            global_models[i] = global_model\n",
    "        return global_models\n",
    "\n",
    "\n",
    "#weight input by cluster size\n",
    "def load_cluster_weights(PATH, hosp):\n",
    "    cluster = pd.read_csv(f'{PATH}{hosp}/clusters.csv')\n",
    "    cluster_weights = cluster.value_counts('cluster')\n",
    "    cluster_df = pd.DataFrame(cluster_weights, columns = ['count'])\n",
    "    cluster_df['site'] = hosp\n",
    "    cluster_df.reset_index(inplace = True)\n",
    "    return cluster_df\n",
    "\n",
    "def site_weight(row):\n",
    "    row['weight'] = row['count'] / row['count'].sum()\n",
    "    return row\n",
    "\n",
    "def calc_weights(PATH, hospitals, cluster):\n",
    "    cluster_sizes = pd.DataFrame()\n",
    "    for hosp in HOSPITALS:\n",
    "        c = load_cluster_weights(PATH, hosp)\n",
    "        cluster_sizes = pd.concat([cluster_sizes, c])\n",
    "    cluster_sizes = cluster_sizes.groupby('cluster').apply(site_weight)\n",
    "    cluster_filter = cluster_sizes[cluster_sizes['cluster']==cluster]\n",
    "    hospitals_cluster = hospitals[[]].merge(cluster_filter[['count', 'site', 'weight']], left_index = True, right_on='site')\n",
    "    hospitals_cluster.set_index('site', inplace = True)\n",
    "    return hospitals_cluster\n",
    "\n",
    "\n",
    "        \n",
    "#COORDINATION\n",
    "def clear_clients(hosp, model):\n",
    "    ##clear models from clients\n",
    "    command = f'rm {PATH}{hosp}/{model}.pt ' \n",
    "    subprocess.call(command, shell = True)\n",
    "    return\n",
    "\n",
    "def run_clients(hosp, model, run, task = None):\n",
    "    command = f'python {PATH_FL_SCRIPT}client_{model}.py -cl={hosp} -rn={run} -tk={task} -mt={MODELTYPE}'\n",
    "    command = command.split(' ')\n",
    "    output = subprocess.check_output(command) \n",
    "    server_response = output.decode('utf-8').split(' ')\n",
    "    return server_response\n",
    "\n",
    "def run_private_clustering(MODELTYPE):\n",
    "    #run private clustering\n",
    "    command = f'python {PATH_FL_SCRIPT}server_private.py -mt={MODELTYPE}'\n",
    "    command = command.split(' ')\n",
    "    output = subprocess.check_output(command) \n",
    "    server_response = output.decode('utf-8').split(' ')\n",
    "    return server_response\n",
    "\n",
    "def run_prediction(hospitals, iteration, MODE):\n",
    "    #########PREDICTION TASK#########\n",
    "    MODEL = 'prediction'\n",
    "    TASK = 'mortality'\n",
    "    ROUNDS = 15\n",
    "    \n",
    "    ##Initialize model for each cluster\n",
    "    dim0, dim1, dim2 = list(DIMS.values())\n",
    "    initial_model = FeedForward(dim0, dim1, dim2)\n",
    "    for hosp in hospitals.index:\n",
    "        site_clusters = np.loadtxt(f'{PATH}{hosp}/site_clusters', dtype = int)\n",
    "        site_clusters = np.atleast_1d(site_clusters)\n",
    "        for i in site_clusters:\n",
    "            torch.save(initial_model.state_dict(), f'{PATH}{hosp}/{MODEL}_cluster_{i}.pt')\n",
    "\n",
    "    # Training part        \n",
    "    # ##Run prediction models for multiple rounds\n",
    "    # for i in range(ROUNDS):\n",
    "    #     RUN = 'train'\n",
    "    #     futures = []\n",
    "    #     with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    #         for hosp in hospitals.index:\n",
    "    #             futures.append(executor.submit(run_clients,hosp, MODEL, RUN))\n",
    "    #     concurrent.futures.wait(futures)\n",
    "\n",
    "        # ##Average\n",
    "        # global_models = runFedAvg(hospitals, MODEL, MODE)\n",
    "        # #save\n",
    "        # for hosp in hospitals.index:\n",
    "        #     site_clusters = np.loadtxt(f'{PATH}{hosp}/site_clusters', dtype = int)\n",
    "        #     site_clusters = np.atleast_1d(site_clusters)\n",
    "        #     for i in site_clusters:\n",
    "        #         global_model = global_models[i]\n",
    "        #         torch.save(global_model.state_dict(), f'{PATH}{hosp}/prediction_cluster_{i}.pt') \n",
    "\n",
    "#    ##After training save global model for inference\n",
    "#     for hosp in hospitals.index:\n",
    "#         site_clusters = np.loadtxt(f'{PATH}{hosp}/site_clusters', dtype = int)\n",
    "#         site_clusters = np.atleast_1d(site_clusters)\n",
    "#         for i in site_clusters:\n",
    "#             global_model = global_models[i]\n",
    "#             torch.save(global_model.state_dict(), f'{PATH}{hosp}/global_prediction_cluster_{i}.pt') \n",
    "    \n",
    "    ##Inference   \n",
    "    RUN = 'test'\n",
    "    futures = []\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for hosp in hospitals.index:\n",
    "            futures.append(executor.submit(run_clients,hosp, MODEL, RUN))\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "    ##Get reuslts\n",
    "    results = pd.DataFrame(columns = ['cluster', 'AUC', 'site'])\n",
    "    results_auprc = pd.DataFrame(columns = ['cluster', 'AUPRC', 'site'])\n",
    "    for hosp in hospitals.index:\n",
    "        result_site = pd.read_csv( f'{PATH}{hosp}/results.csv')\n",
    "        result_site_auprc = pd.read_csv( f'{PATH}{hosp}/results_auprc.csv')\n",
    "        result_site['site'] = hosp\n",
    "        result_site_auprc['site'] = hosp\n",
    "        results = pd.concat([results, result_site])\n",
    "        results_auprc = pd.concat([results_auprc, result_site_auprc])\n",
    "\n",
    "    ## Check if the average AUC is less than or equal to 0.5 i.e. wehther model learned\n",
    "    if results['AUC'].mean() <= 0.5:\n",
    "        print(\"Average AUC is less than or equal to 0.5. Rerunning the function...\")\n",
    "        return run_prediction(hospitals, iteration, MODE)\n",
    "    else:\n",
    "        ##Save results\n",
    "        results.to_csv(f'{PATH}{TASK}_results_{iteration}.csv', index = False)\n",
    "        results_auprc.to_csv(f'{PATH}{TASK}_results_auprc_{iteration}.csv', index = False)\n",
    "        return\n",
    "\n",
    "\n",
    "def run_prediction_avg(hospitals, iteration, MODE):\n",
    "        #########PREDICTION TASK#########\n",
    "    MODEL = 'prediction'\n",
    "    TASK = 'mortality'\n",
    "    ROUNDS = 15\n",
    "    \n",
    "    ##Initialize model for each cluster\n",
    "    dim0, dim1, dim2 = list(DIMS.values())\n",
    "    initial_model = FeedForward(dim0, dim1, dim2)\n",
    "    for hosp in hospitals.index:\n",
    "        torch.save(initial_model.state_dict(), f'{PATH}{hosp}/{MODEL}.pt')\n",
    "\n",
    "            \n",
    "    ##Run prediction models for multiple rounds\n",
    "    # for i in range(ROUNDS):\n",
    "    #     RUN = 'train'\n",
    "    #     futures = []\n",
    "    #     with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    #         for hosp in hospitals.index:\n",
    "    #             futures.append(executor.submit(run_clients,hosp, MODEL, RUN))\n",
    "    #     concurrent.futures.wait(futures)\n",
    "\n",
    "#         ##Average\n",
    "#         global_model = runFedAvg(hospitals, MODEL, MODE)\n",
    "#         #save\n",
    "#         for hosp in hospitals.index:\n",
    "#             torch.save(global_model.state_dict(), f'{PATH}{hosp}/prediction.pt') \n",
    "\n",
    "#    ##After training save global model for inference\n",
    "#     for hosp in hospitals.index:\n",
    "#         torch.save(global_model.state_dict(), f'{PATH}{hosp}/global_prediction.pt') \n",
    "\n",
    "    ##Inference   \n",
    "    RUN = 'test'\n",
    "    futures = []\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for hosp in hospitals.index:\n",
    "            futures.append(executor.submit(run_clients,hosp, MODEL, RUN))\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "    ##Get reuslts\n",
    "    results = pd.DataFrame(columns = ['site', 'AUC'])\n",
    "    results_auprc = pd.DataFrame(columns = ['site', 'AUPRC'])\n",
    "    for hosp in hospitals.index:\n",
    "        result_site = pd.read_csv( f'{PATH}{hosp}/results.csv')\n",
    "        result_site_auprc = pd.read_csv( f'{PATH}{hosp}/results_auprc.csv')\n",
    "        results = pd.concat([results, result_site])\n",
    "        results_auprc = pd.concat([results_auprc, result_site_auprc])\n",
    "\n",
    "    ## Check if the average AUC is less than or equal to 0.5 i.e. wehther model learned\n",
    "    if results['AUC'].mean() <= 0.5:\n",
    "        print(\"Average AUC is less than or equal to 0.5. Rerunning the function...\")\n",
    "        if MODELTYPE == 'avg':\n",
    "            return run_prediction_avg(hospitals, iteration, MODE)\n",
    "        else:\n",
    "            return run_prediction(hospitals, iteration, MODE)\n",
    "    else:\n",
    "        ##Save results\n",
    "        results.to_csv(f'{PATH}{TASK}_{MODEL}_results_{iteration}.csv', index = False)\n",
    "        results_auprc.to_csv(f'{PATH}{TASK}_{MODEL}_results_auprc_{iteration}.csv', index = False)\n",
    "        return\n",
    "\n",
    "def main(iteration):\n",
    "    #Load hospitals\n",
    "    hospitals = pd.read_csv(f'{PATH_DATA}hospitals.csv', index_col = 'hospitalid')\n",
    "\n",
    "    if MODELTYPE  == 'cbfl':\n",
    "        MODE = 'cluster'\n",
    "        run_prediction(hospitals, iteration, MODE)\n",
    "    else:\n",
    "        if (MODELTYPE  == 'emb') | (MODELTYPE  == 'p_cbfl'):\n",
    "            #run_private_clustering(MODELTYPE)\n",
    "            MODE = 'cluster'\n",
    "            run_prediction(hospitals, iteration, MODE)\n",
    "        elif MODELTYPE == 'avg':\n",
    "            hospitals['weight'] = hospitals['count'] / hospitals['count'].sum()\n",
    "            MODE = 'all'\n",
    "            run_prediction_avg(hospitals, iteration, MODE)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea138e9",
   "metadata": {},
   "source": [
    "#### Evaluation of the model p_cfbl\n",
    "To calculate the overall AUC and AUPRC (Global R) for CBFL and PCBFL, the paper uses a weighted average of results that takes into account the number of patients each site contributes to a cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36aa00d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5732117135754304\n"
     ]
    }
   ],
   "source": [
    "global PATH\n",
    "MODELTYPE = \"p_cbfl\"\n",
    "PATH = '/home/xhe33/pcfbl/'\n",
    "    \n",
    "main(93)\n",
    "results_path = '/home/xhe33/pcfbl/mortality_results_93.csv'\n",
    "results_df = pd.read_csv(results_path)\n",
    "results_df_cleaned = results_df.dropna(subset=['AUC'])\n",
    "cluster_weights = results_df_cleaned.groupby(['site', 'cluster']).size().reset_index(name='count')\n",
    "total_counts = cluster_weights.groupby('site')['count'].sum().reset_index(name='total_count')\n",
    "cluster_weights = cluster_weights.merge(total_counts, on='site')\n",
    "cluster_weights['weight'] = cluster_weights['count'] / cluster_weights['total_count']\n",
    "merged_df = results_df_cleaned.merge(cluster_weights, on=['site', 'cluster'])\n",
    "# Multiply each AUC by its weight and sum the products to get the numerator for Global R\n",
    "weighted_auc_sum = (merged_df['AUC'] * merged_df['weight']).sum()\n",
    "# The denominator N is the sum of all weights\n",
    "N = cluster_weights['weight'].sum()\n",
    "global_r_weighted = weighted_auc_sum / N\n",
    "print(global_r_weighted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f583f31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4111052946496505\n"
     ]
    }
   ],
   "source": [
    "# AUPRC\n",
    "results_path = '/home/xhe33/pcfbl/mortality_results_auprc_93.csv'\n",
    "results_df = pd.read_csv(results_path)\n",
    "results_df_cleaned = results_df.dropna(subset=['AUPRC'])\n",
    "cluster_weights = results_df_cleaned.groupby(['site', 'cluster']).size().reset_index(name='count')\n",
    "total_counts = cluster_weights.groupby('site')['count'].sum().reset_index(name='total_count')\n",
    "cluster_weights = cluster_weights.merge(total_counts, on='site')\n",
    "cluster_weights['weight'] = cluster_weights['count'] / cluster_weights['total_count']\n",
    "merged_df = results_df_cleaned.merge(cluster_weights, on=['site', 'cluster'])\n",
    "# Multiply each AUPRC by its weight and sum the products to get the numerator for Global R\n",
    "weighted_auc_sum = (merged_df['AUPRC'] * merged_df['weight']).sum()\n",
    "# The denominator N is the sum of all weights\n",
    "N = cluster_weights['weight'].sum()\n",
    "global_r_weighted = weighted_auc_sum / N\n",
    "print(global_r_weighted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a9719",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc4801",
   "metadata": {},
   "source": [
    "#### Compared to traditional federated learning model FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ec7f131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5741788666421009\n"
     ]
    }
   ],
   "source": [
    "global PATH\n",
    "MODELTYPE = \"avg\"\n",
    "PATH = '/home/xhe33/pcfbl/'\n",
    "main(93)\n",
    "results_path = '/home/xhe33/pcfbl/mortality_prediction_results_93.csv'\n",
    "results_df = pd.read_csv(results_path)\n",
    "global_r = results_df['AUC'].mean(skipna=True)\n",
    "print(global_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb77ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4156562011933755\n"
     ]
    }
   ],
   "source": [
    "global PATH\n",
    "MODELTYPE = \"avg\"\n",
    "PATH = '/home/xhe33/pcfbl/'\n",
    "main(93)\n",
    "results_path = '/home/xhe33/pcfbl/mortality_prediction_results_auprc_93.csv'\n",
    "results_df = pd.read_csv(results_path)\n",
    "global_r = results_df['AUPRC'].mean(skipna=True)\n",
    "print(global_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d0d644b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-ab23b7721495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.7133\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5742\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5732\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Global AUC by Model Type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# results  AUC\n",
    "categories = ['Centralized', 'FedAvg', 'PCBFL']  \n",
    "values = [0.7133, 0.5742, 0.5732]  \n",
    "  \n",
    "plt.figure(figsize=(10, 5))  \n",
    "plt.bar(categories, values)  \n",
    "plt.title('Global AUC by Model Type')  \n",
    "plt.xlabel('Model')  \n",
    "plt.ylabel('AUC')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15898d6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-ef008653a27a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.5034\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4156\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4111\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Global AUPRC by Model Type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# results  \n",
    "categories = ['Centralized', 'FedAvg', 'PCBFL']  \n",
    "values = [0.5034, 0.4156, 0.4111]  \n",
    "  \n",
    "plt.figure(figsize=(10, 5))  \n",
    "plt.bar(categories, values)  \n",
    "plt.title('Global AUPRC by Model Type')  \n",
    "plt.xlabel('Model')  \n",
    "plt.ylabel('AUPRC')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650b89c",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "This research aimed to assess the reproducibility of a paper detailing Privacy-preserving Community-Based Federated Learning (PCBFL). The results of our reproduction effort, though not entirely aligning with the ideal outcomes reported in the original study, provided significant insights into the reproducibility of the paper and highlighted challenges faced during the process. \n",
    "\n",
    "What was easy: The paper provided a comprehensive explanation of the PCBFL approach, along with detailed algorithms and pseudocode, which facilitated the understanding of the proposed methodology.\n",
    "\n",
    "What was difficult: The intergration of the different modules as well as the calculation of the weights based on the cluster results for each sites. The choice of the sampling numbers and the hyperparameters.\n",
    "\n",
    "Suggestions for Improvement: for future reproducibility efforts, it would be beneficial if the authors could provide the detailed setting of the hyperparameters.\n",
    "\n",
    "Next Steps: \n",
    "* Assessing the performance of the CBFL model\n",
    "* Examing the clinical relevance of clusters\n",
    "* Assessing the generalizability across sites\n",
    "* Ablation study of patient embedding learning\n",
    "* Ablation study of patient similarity estimation\n",
    "* Ablation study of patients clustering\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32286c3",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1.   Elhussein A, Gürsoy G. Privacy-preserving patient clustering for personalized federated learnings[C]//Machine Learning for Healthcare Conference. PMLR, 2023: 150-166."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abdeafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
